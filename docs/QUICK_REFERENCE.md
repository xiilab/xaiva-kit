# ë¹ ë¥¸ ì°¸ì¡° ê°€ì´ë“œ

## ğŸš€ í•œëˆˆì— ë³´ëŠ” ëª…ë ¹ì–´

### ë¹Œë“œ

```bash
# ëŒ€í™”í˜• ë¹Œë“œ
python3 scripts/build.py

# ìë™ ë¹Œë“œ
python3 scripts/build.py --preset ubuntu22.04-cuda11.8-torch2.1 --non-interactive

# Dry-run (ëª…ë ¹ì–´ë§Œ í™•ì¸)
python3 scripts/build.py --preset ubuntu22.04-cuda11.8-torch2.1 --dry-run

# í”„ë¦¬ì…‹ ëª©ë¡
python3 scripts/build.py --list-presets
```

### ì‹¤í–‰

```bash
# ì´ë¯¸ì§€ ì‹¤í–‰
docker run --rm -it --gpus all xaiva-kit:ubuntu22.04-cuda11.8-torch2.1 /bin/bash

# ì†ŒìŠ¤ ë§ˆìš´íŠ¸ì™€ í•¨ê»˜ ì‹¤í–‰
docker run --rm -it --gpus all -v $(pwd)/xaiva-kit:/workspace/xaiva-media \
  xaiva-kit:ubuntu22.04-cuda11.8-torch2.1 /bin/bash

# ë°ëª¬ ëª¨ë“œë¡œ ì‹¤í–‰
docker run -d --gpus all --name xaiva-container xaiva-kit:ubuntu22.04-cuda11.8-torch2.1
```

### ì˜¤í”„ë¼ì¸ ë°°í¬

```bash
# ì´ë¯¸ì§€ ì €ì¥
docker save xaiva-kit:ubuntu22.04-cuda11.8-torch2.1 > xaiva-kit.tar

# ì´ë¯¸ì§€ ë¡œë“œ
docker load < xaiva-kit.tar

# ì´ë¯¸ì§€ ì••ì¶• (ë” ì‘ì€ íŒŒì¼)
docker save xaiva-kit:ubuntu22.04-cuda11.8-torch2.1 | gzip > xaiva-kit.tar.gz
docker load < xaiva-kit.tar.gz
```

### ì´ë¯¸ì§€ ê´€ë¦¬

```bash
# ì´ë¯¸ì§€ ëª©ë¡
docker images | grep xaiva-media

# ì´ë¯¸ì§€ ì‚­ì œ
docker rmi xaiva-kit:ubuntu22.04-cuda11.8-torch2.1-runtime

# ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ ì •ë¦¬
docker image prune -a

# ì´ë¯¸ì§€ ì •ë³´ í™•ì¸
docker inspect xaiva-kit:ubuntu22.04-cuda11.8-torch2.1-runtime
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë¹Œë“œ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] Docker ì„¤ì¹˜ í™•ì¸: `docker --version`
- [ ] NVIDIA Container Toolkit í™•ì¸: `nvidia-container-toolkit --version`
- [ ] GPU ì¸ì‹ í™•ì¸: `nvidia-smi`
- [ ] ë””ìŠ¤í¬ ê³µê°„ í™•ì¸: `df -h` (ìµœì†Œ 20GB)
- [ ] ì¸í„°ë„· ì—°ê²° í™•ì¸ (Python íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œìš©)

### ë¹Œë“œ í›„ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] ì´ë¯¸ì§€ ìƒì„± í™•ì¸: `docker images | grep xaiva-media`
- [ ] ì´ë¯¸ì§€ í¬ê¸° í™•ì¸ (Runtime: ~10-15GB)
- [ ] ì»¨í…Œì´ë„ˆ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
- [ ] GPU ì ‘ê·¼ í™•ì¸: `nvidia-smi` (ì»¨í…Œì´ë„ˆ ë‚´)
- [ ] Python ë²„ì „ í™•ì¸: `python --version`
- [ ] PyTorch í™•ì¸: `python -c "import torch; print(torch.__version__)"`
- [ ] CUDA ì‚¬ìš© ê°€ëŠ¥ í™•ì¸: `python -c "import torch; print(torch.cuda.is_available())"`
- [ ] TensorRT í™•ì¸: `python -c "import tensorrt; print(tensorrt.__version__)"`

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ë¹Œë“œ ì‹¤íŒ¨

```bash
# 1. ë¡œê·¸ í™•ì¸
docker logs <container-id>

# 2. ì¤‘ê°„ ìŠ¤í…Œì´ì§€ í™•ì¸
docker ps -a

# 3. ìºì‹œ ë¬´ì‹œí•˜ê³  ë‹¤ì‹œ ë¹Œë“œ
docker build --no-cache ...

# 4. ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ
docker build --memory=8g --cpus=4 ...
```

### GPU ì¸ì‹ ì•ˆ ë¨

```bash
# 1. NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# 2. Docker GPU ì§€ì› í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi

# 3. Docker ì¬ì‹œì‘
sudo systemctl restart docker

# 4. ì»¨í…Œì´ë„ˆ GPU í”Œë˜ê·¸ í™•ì¸
docker run --gpus all ...  # 'all' ë˜ëŠ” 'device=0,1'
```

### Python íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤íŒ¨

```bash
# 1. ì¸í„°ë„· ì—°ê²° í™•ì¸
ping pypi.org

# 2. PyTorch ì¸ë±ìŠ¤ í™•ì¸
curl https://download.pytorch.org/whl/torch_stable.html

# 3. í”„ë¡ì‹œ ì„¤ì • (í•„ìš”ì‹œ)
docker build --build-arg HTTP_PROXY=http://proxy:port ...

# 4. pip ìºì‹œ ì •ë¦¬
docker build --no-cache ...
```

---

## ğŸ“Š ë¹ ë¥¸ í†µê³„

### ë¹Œë“œ ì‹œê°„

| í•­ëª© | ì‹œê°„ (ì˜ˆìƒ) |
|------|-------------|
| ì½”ë± ë¼ì´ë¸ŒëŸ¬ë¦¬ | 15-30ë¶„ |
| FFmpeg | 10-20ë¶„ |
| OpenCV (CUDA) | 30-60ë¶„ |
| Xaiva Media | 10-20ë¶„ |
| Python íŒ¨í‚¤ì§€ | 10-20ë¶„ |
| **ì „ì²´** | **1-2ì‹œê°„** |

### ë””ìŠ¤í¬ ì‚¬ìš©ëŸ‰

| í•­ëª© | í¬ê¸° (ì˜ˆìƒ) |
|------|-------------|
| Builder ì´ë¯¸ì§€ | ~20GB |
| Runtime ì´ë¯¸ì§€ | ~10-15GB |
| Dev ì´ë¯¸ì§€ | ~20GB |
| artifacts/ | ~5-10GB |

---

## ğŸ¯ ì£¼ìš” ê²½ë¡œ

### ì»¨í…Œì´ë„ˆ ë‚´ë¶€ ê²½ë¡œ

```
/usr/local/bin/              # ì‹¤í–‰ íŒŒì¼ (FFmpeg, xaiva-app ë“±)
/usr/local/lib/              # ë¼ì´ë¸ŒëŸ¬ë¦¬ (.so íŒŒì¼)
/usr/local/include/          # í—¤ë” íŒŒì¼
/usr/local/cuda/             # CUDA ì„¤ì¹˜ ê²½ë¡œ
```

### í˜¸ìŠ¤íŠ¸ í”„ë¡œì íŠ¸ ê²½ë¡œ

```
artifacts/<preset-name>/     # í”„ë¦¬ì…‹ë³„ ì•„í‹°íŒ©íŠ¸
  â”œâ”€â”€ wheels/                # Python wheels (í˜„ì¬ ë¯¸ì‚¬ìš©)
  â”œâ”€â”€ sources/               # ì†ŒìŠ¤ ì•„ì¹´ì´ë¸Œ
  â””â”€â”€ requirements.txt       # Python íŒ¨í‚¤ì§€ ëª©ë¡

presets/<preset-name>.json   # í”„ë¦¬ì…‹ ì •ì˜
docker/Dockerfile            # Multi-stage Dockerfile
scripts/build.py             # ë¹Œë“œ ë“œë¼ì´ë²„
```

---

## ğŸ”‘ ì£¼ìš” í™˜ê²½ ë³€ìˆ˜

### ë¹Œë“œ ì‹œ

```bash
# Dockerfile ARG
BASE_IMAGE=nvidia/cuda:11.8.0-cudnn8-devel-ubuntu22.04
PRESET_NAME=ubuntu22.04-cuda11.8-torch2.1
PYTHON_VERSION=3.10
CUDA_ARCH=86
FFMPEG_VERSION=4.2
OPENCV_VERSION=4.9.0
```

### ëŸ°íƒ€ì„

```bash
# ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í™˜ê²½ ë³€ìˆ˜
PATH=/usr/local/bin:/usr/bin:/bin
LD_LIBRARY_PATH=/usr/local/lib:/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64
NVIDIA_VISIBLE_DEVICES=all
NVIDIA_DRIVER_CAPABILITIES=video,compute,utility
TZ=Asia/Seoul
LC_ALL=C.UTF-8
```

---

## ğŸ“¦ í”„ë¦¬ì…‹ í•„ë“œ ìš”ì•½

```json
{
  "metadata": { "name", "description", "created", "target_gpu" },
  "base_image": "nvidia/cuda:...",
  "python": { "version": "3.10", "version_without_dot": "310" },
  "pytorch": { "torch_version": "2.1.0+cu118", ... },
  "tensorrt": { "version": "8.6.1", "required_in_runtime": true, ... },
  "cuda": { "version": "11.8", "arch": "86" },
  "build_options": { "ffmpeg_version", "opencv_version", ... },
  "system_packages": [...],
  "environment": { "LD_LIBRARY_PATH", ... }
}
```

---

## ğŸ› ë””ë²„ê¹… íŒ

### ì»¨í…Œì´ë„ˆ ë‚´ë¶€ í™•ì¸

```bash
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± í™•ì¸
ldd /usr/local/bin/xaiva-app

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²€ìƒ‰ ê²½ë¡œ í™•ì¸
ldconfig -p | grep libxaiva

# Python íŒ¨í‚¤ì§€ í™•ì¸
pip list | grep torch

# CUDA í™•ì¸
nvcc --version
nvidia-smi

# í™˜ê²½ ë³€ìˆ˜ í™•ì¸
echo $LD_LIBRARY_PATH
echo $PATH
```

### ë¡œê·¸ í™•ì¸

```bash
# Docker ë¹Œë“œ ë¡œê·¸ ì €ì¥
python3 scripts/build.py ... 2>&1 | tee build.log

# ì»¨í…Œì´ë„ˆ ë¡œê·¸
docker logs <container-id>

# ë¹Œë“œ íˆìŠ¤í† ë¦¬ í™•ì¸
docker history xaiva-kit:ubuntu22.04-cuda11.8-torch2.1-runtime
```

---

## ğŸ“ ë„ì›€ë§ ë° ë¬¸ì„œ

### CLI ë„ì›€ë§

```bash
# build.py ë„ì›€ë§
python3 scripts/build.py --help

# Docker ë„ì›€ë§
docker build --help
docker run --help
```

### ë¬¸ì„œ ë§í¬

| ë¬¸ì„œ | ê²½ë¡œ |
|------|------|
| ë¹Œë“œ ê°€ì´ë“œ | `docs/build-guide.md` |
| í”„ë¦¬ì…‹ ìŠ¤í‚¤ë§ˆ | `docs/preset-schema.md` |
| í”„ë¡œì íŠ¸ ìš”ì•½ | `docs/PROJECT_SUMMARY.md` |
| ê°œë°œ íˆìŠ¤í† ë¦¬ | `docs/DEVELOPMENT_HISTORY.md` |
| ë¬¸ì„œ ê°€ì´ë“œ | `docs/README.md` |

---

## ğŸ’¡ ìœ ìš©í•œ íŒ

### ë¹Œë“œ ìµœì í™”

```bash
# BuildKit ì‚¬ìš© (ë” ë¹ ë¥¸ ë¹Œë“œ)
DOCKER_BUILDKIT=1 docker build ...

# ë³‘ë ¬ ë¹Œë“œ ì œí•œ (ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ)
export MAKEFLAGS="-j4"  # 4ì½”ì–´ë§Œ ì‚¬ìš©

# ë¹Œë“œ ìºì‹œ í™œìš©
docker build --cache-from=xaiva-kit:latest ...
```

### ì´ë¯¸ì§€ í¬ê¸° ìµœì í™”

```bash
# ë¶ˆí•„ìš”í•œ ë ˆì´ì–´ í™•ì¸
docker history xaiva-kit:ubuntu22.04-cuda11.8-torch2.1-runtime

# ì´ë¯¸ì§€ ì••ì¶•
docker-squash xaiva-kit:ubuntu22.04-cuda11.8-torch2.1-runtime

# ë‹¤ë‹¨ê³„ ë¹Œë“œ ì‚¬ìš© (ì´ë¯¸ ì ìš©ë¨)
# builder, runtime ë¶„ë¦¬
```

### ì—¬ëŸ¬ í”„ë¦¬ì…‹ ë¹Œë“œ

```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
for preset in ubuntu22.04-cuda11.8-torch2.1 ubuntu22.04-cuda12.1-torch2.3; do
  python3 scripts/build.py --preset $preset --build-type runtime --non-interactive
done
```

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-11-21  
**ë²„ì „**: 1.0

